---
title: "Week 4 - Simulation and Profiling"
output:
  pdf_document:
    toc: yes
    toc_depth: 6
    number_sections: yes
    latex_engine: xelatex
    df_print: kable
    highlight: tango
  html_notebook: default
  html_document:
    toc: yes
    toc_depth: '6'
    df_print: paged
  word_document:
    toc: yes
    toc_depth: '6'
---

# Week 4 - Simulation & Profiling

## The str Function

str: Completly display the internal structyure of an R object 

- A diagnostic function and an alternative to 'summary'     
- It is especially well suited to compactly display the (abbreviated) contents of (spossibly nester) lists.   
- Roughly one line per basic object   


```{r}
str(str)
```
```{r}
str(lm)
```

```{r}
x <- rnorm(100, 2, 4)
x
```
```{r}
summary(x)
```
```{r}
str(x)
```

x is a numeric vector, has 100 elements in it, and gives first 5 elements.

```{r}
f <- gl(40,10)
str(f)
```

```{r}
summary(f)
```
```{r}
library(datasets)
head(airquality)
```
```{r}
str(airquality)
```
```{r}
m <- matrix(rnorm(100,10,10))
str(m)
```
```{r}
m[,1]
```
```{r}
s <- split(airquality, airquality$Month)
s
```

```{r}
str(s)
```

## Simulation - Generating Random Numbers

Functions for probability distributions in R 

· rnorm: generate random Normal variates with a given mean and standard deviation
· dnorm: evaluate the Normal probability density (with a given mean/SD) at a point (or vector of points)
· pnorm: evaluate the cumulative distribution function for a Normal distribution
· rpois: generate random Poisson variates with a given rate


Probability distribution functions usually have four functions associated with them. The functions are prefixed with a
· d for density
· r for random number generation
· p for cumulative distribution
· q for quantile function

Working with the Normal distributions requires using these four functions 

```
dnorm(x, mean = 0, sd = 1, log = FALSE)
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) 
qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) 
rnorm(n, mean = 0, sd = 1)
```

If Φ is the cumulative distribution function for a standard Normal distribution, then pnorm(q) = Φ(q) and qnorm(p) = Φ−1 (p).


```{r}
x <- rnorm(10)
x
```
```{r}
hist(x)
```


```{r}
x <- rnorm(10,20,2)
x
```
```{r}
hist(x)
```

```{r}
summary(x)
```


Setting the random number seed with set.seed ensures reproducibility 

```{r}
set.seed(1)
rnorm(5)
```

```{r}
rnorm(5)
```

```{r}
set.seed(1)
rnorm(5)
```

Always set the random number seed when conducting a simulation! 

Generating Poisson data

```{r}
rpois(10, 1)
```
```{r}
hist(rpois(10, 1))
```

```{r}
rpois(10, 20)
hist(rpois(10, 20))
```


```{r}
ppois(2, 2) ## Cumulative distribution
```
Pr(x <= 2)

```{r}
ppois(6, 2)
```
Pr(x <= 6)

```{r}
ppois(4, 2)
```
Pr(x <= 4)

### Generating Random Numbers From a Linear Model

Suppose we want to simulate from the following linear model 

y=β0 +β1x+ε

where ε ∼ N(0,22). Assume x ∼ N(0,12), β0 = 0.5 and β1 = 2. 

```{r}
set.seed(20)
x <- rnorm(100)
e <- rnorm(100, 0, 2)
y<-0.5+2*x+e
```

```{r}
summary(y)
```
```{r}
y
```

```{r}
plot(x, y)
```

What if x is binary?

```{r}
set.seed(10)
x <- rbinom(100, 1, 0.5)
e <- rnorm(100, 0, 2)
y<-0.5+2*x+e
y 
```

```{r}
summary(y)
```
```{r}
plot(x,y)
```

Suppose we want to simulate from a Poisson model where

Y ~ Poisson(μ)
logμ=β0 +β1x

and β0 = 0.5 and β1 = 0.3. We need to use the rpois function for this

```{r}
set.seed(1)
x <- rnorm(100)
log.mu<-0.5+0.3*x
y <- rpois(100, exp(log.mu))
summary(y)
```

```{r}
plot(x,y)
```

### Random Sampling

The sample function draws randomly from a specified set of (scalar) objects allowing you to sample from arbitrary distributions.

```{r}
set.seed(1)
sample(1:10, 4)
```

```{r}
sample(1:10, 4)
```

```{r}
sample(letters, 5)
```

```{r}
sample(1:10) ## permutation
```

```{r}
sample(1:10)
```

```{r}
sample(1:10, replace = TRUE) ## Sample w/replacement
```

Summary
· Drawing samples from specific probability distributions can be done with r* functions
· Standard distributions are built in: Normal, Poisson, Binomial, Exponential, Gamma, etc.
· The sample function can be used to draw random samples from arbitrary vectors
· Setting the random number generator seed via set.seed is critical for reproducibility


## R Profiler

### Why is My Code So Slow?

Profiling is a systematic way to examine how much time is spend in different parts of a program
· Useful when trying to optimize your code
· Often code runs fine once, but what if you have to put it in a loop for 1,000 iterations? Is it still fast enough?
· Profiling is better than guessing

### On Optimizing Your Code

· Getting biggest impact on speeding up code depends on knowing where the code spends most of its time
· This cannot be done without performance analysis or profiling 

We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil
--Donald Knuth 

### General Principles of Optimization

· Design first, then optimize
· Remember: Premature optimization is the root of all evil
· Measure (collect data), don’t guess.
· If you're going to be scientist, you need to apply the same principles here!

### Using system.time()

· Takes an arbitrary R expression as input (can be wrapped in curly braces) and returns the
amount of time taken to evaluate the expression
· Computes the time (in seconds) needed to execute an expression
- Ifthere’sanerror,givestimeuntiltheerroroccurred
· Returns an object of class proc_time
- usertime:timechargedtotheCPU(s)forthisexpression - elapsedtime:"wallclock"time

· Usually, the user time and elapsed time are relatively close, for straight computing tasks
· Elapsed time may be greater than user time if the CPU spends a lot of time waiting around
· Elapsted time may be smaller than the user time if your machine has multiple cores/processors (and is capable of using them)
- Multi-threadedBLASlibraries(vecLib/Accelerate,ATLAS,ACML,MKL) - Parallelprocessingviatheparallelpackage

```{r}
## Elapsed time > user time
system.time(readLines("http://www.jhsph.edu"))
```

```{r}
## Elapsed time < user time
hilbert <- function(n) {
  i <- 1:n
  1 / outer(i - 1, i, "+")
}

x <- hilbert(1000)
system.time(svd(x))
```

### Timing Longer Expressions

```{r}
system.time({
  n <- 1000
  r <- numeric(n) 
  for (i in 1:n) {
    x <- rnorm(n)
    r[i] <- mean(x)
  }
})
```

`user`: The CPU time charged for the execution of user instructions of the calling process. This is the time spent by the CPU executing the code.    

`system`: The CPU time charged for execution by the system on behalf of the calling process. This often refers to time spent on system-level tasks such as memory allocation.

`elapsed`: The total elapsed (wall-clock) time in seconds. This is essentially the real-world time it took for the code to run start-to-finish. It's usually the sum of user and system times, but can be greater due to reasons like if your process is running on a multitasking system and gets paused to allow other tasks to run.


### Beyond system.time()

- Using system.time() allows you to test certain functions or code blocks to see if they are taking
excessive amounts of time 

- Assumes you already know where the problem is and can call system.time() on it

- What if you don’t know where to start?

### The R Profiler

· The Rprof() function starts the profiler in R
- Rmustbecompiledwithprofilersupport(butthisisusuallythecase)
· The summaryRprof() function summarizes the output from Rprof() (otherwise it’s not readable)
· DO NOT use system.time() and Rprof() together or you will be sad

· Rprof() keeps track of the function call stack at regularly sampled intervals and tabulates how much time is spend in each function
· Default sampling interval is 0.02 seconds
· NOTE: If your code runs very quickly, the profiler is not useful, but then you probably don't need it in that case

```{r}
##lm(y~x)

sample.interval=10000
```

### Using summaryRprof()

· The summaryRprof() function tabulates the R profiler output and calculates how much time is
spend in which function
· There are two methods for normalizing the data
· "by.total" divides the time spend in each function by the total run time
· "by.self" does the same but first subtracts out time spent in functions above in the call stack

### By Total

```{r,error=TRUE}
$by.total
```

```{r,error=TRUE}
$by.self
```

```{r}
sample.interval
```

Summary
· Rprof() runs the profiler for performance of analysis of R code
· summaryRprof() summarizes the output of Rprof() and gives percent of time spent in each
function (with two types of normalization)
· Good to break your code into functions so that the profiler can give useful information about where time is being spent
· C or Fortran code is not profiled



