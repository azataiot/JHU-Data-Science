file.exists("data")
if(!file.exists("data")){
dir.create("data")
}
str(download.file)
knitr::include_graphics("assets/1.png")
fileUrl <- "https://opendata.arcgis.com/api/v3/datasets/cc4d3f4c436d4736b121ce781d4f86de_0/downloads/data?format=csv&spatialRefId=2248&where=1%3D1"
download.file(fileUrl, destfile = "./data/cameras.csv", method = "curl")
list.files("./data")
cameraData <- read.table("./data/cameras.csv")
head(cameraData)
cameraData <- read.table("./data/cameras.csv", sep = ",", header = TRUE)
cameraData <- read.table("data/cameras.csv", sep = ",", header = TRUE)
str(read.table)
install.packages("xlsx")
library(xlsx)
str(read.xlsx)
library(xlsx)
colIndex <- 2:3
rowIndex <- 1:4
cameraDataSubset <-
read.xlsx(
"data/data.xlsx",
sheetIndex = 1,
colIndex = colIndex,
rowIndex = rowIndex
)
library(XML)
install.packages("XML")
library(XML)
fileURL <- "https://www.w3schools.com/xml/cd_catalog.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
fileURL <- "https://www.w3schools.com/xml/note.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
doc
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
library(XML)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
library(XML)
fileURL <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
library(XML)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
library(XML)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
download.file(fileUrl, destfile = "./data/simple.xml", method = "curl")
list.files("./data")
library(XML)
# Parse the XML file
doc <- xmlTreeParse("./data/simple.xml", useInternal = TRUE)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
download.file(fileUrl, destfile = "./data/simple.xml", method = "curl")
list.files("./data")
library(XML)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
library(XML)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
library(XML)
fileURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal = TRUE)
library(XML)
xmlURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(xmlURL, useInternal = TRUE)
library(XML)
xmlURL <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(xmlURL, useInternal = TRUE)
xmlURL <- "https://www.w3schools.com/xml/simple.xml"
download.file(xmlURL, destfile = "./data/simple.xml", method = "curl")
list.files("./data")
library(XML)
# Parse the XML file
doc <- xmlTreeParse("data/simple.xml", useInternal = TRUE)
library(XML)
# Parse the XML file
doc <- xmlTreeParse("data/simple.xml", useInternal = TRUE)
doc
rootNode <- xmlRoot(doc)
rootNode
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
xmlSApply(rootNode,xmlValue)
xpathSApply(rootNode, "//name",xmlValue)
xpathSApply(rootNode, "//price",xmlValue)
knitr::include_graphics("assets/2.png")
knitr::include_graphics("assets/3.png")
knitr::include_graphics("assets/3.png")
webURL <- "https://www.espn.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(webURL, useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
install.packages("RCurl")
library(RCurl)
webURL <- "https://www.espn.com/nfl/team/_/name/bal/baltimore-ravens"
webData <- getURL(webURL)
doc <- htmlTreeParse(webData, useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
library(RCurl)
webURL <- "https://www.espn.com/nfl/team/_/name/bal/baltimore-ravens"
webData <- getURL(webURL)
doc <- htmlTreeParse(webData, useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
scores
library(RCurl)
webURL <- "https://www.espn.com/nfl/team/_/name/bal/baltimore-ravens"
webData <- getURL(webURL)
doc <- htmlTreeParse(webData, useInternal=TRUE)
scores <- xpathSApply(doc,"/html/body/div[1]/div/div/div/main/div[2]/div[5]/div/div/section/div/div[9]/div[1]",xmlValue)
scores
install.packages("jsonlite")
repoURL <- https://api.github.com/users/jtleek/repos
repoURL <- "https://api.github.com/users/jtleek/repos"
library(jsonlite)
jsonData <- fromJSON(repoURL)
names(jsonData)
names(jsonData$owner)
jsonData$owner$login
myjson <- toJSON(iris,pretty = TRUE)
cat(myjson)
iris.from <- fromJSON(myjson)
head(iris.from)
install.packages("data.table")
library(data.table)
DF <- data.frame(x = rnorm(9),
y = rep(c("a", "b", "c"), each = 3),
z = rnorm(9))
head(DF,3)
DT = data.table(x=rnonn(9) ,y=rep(c( "a", "b", "c") ,each=3) ,z=rnonn(9))
DT = data.table(x=rnorm(9) ,y=rep(c( "a", "b", "c") ,each=3) ,z=rnorm(9))
DT = data.table(x=rnorm(9) ,y=rep(c( "a", "b", "c") ,each=3) ,z=rnorm(9))
head(DT,3)
tables()
DT[2,]
DT[DT$y=="a",]
DT[c(2,3)]
DT[,c(2,3)]
{
X = 1
y = 2
}
k = {print(lO); 5}
{
X = 1
y = 2
}
k = {print(10); 5}
print(k)
DT[,list(mean(x),sum(z))]
DT[ ,table(y)]
DT[,w:z^2]
DT[,w:=z^2]
DT[,w:=z^2]
head(DT)
DT2 <- DT
DT[,y:=2]
DT2 <- DT
DT[,y:=2]
head(DT)
head(DT,n=3)
head(DT2,n=3)
DT[,m:= {tmp <- (x+z); log2(tmp+5)}]
DT[,m:= {tmp <- (x+z); log2(tmp+5)}]
head(DT)
DT[ ,a:=x>0]
head(DT)
DT[ ,b:= mean(x+w) ,by=a]
head(DT)
set.seed(123)
DT <- data.table(x=sample(letters[1:3],1E5,TRUE))
head(DT)
DT[,.N,by=x]
DT <- data.table(x=rep(c("a","b","c"),each=100), y=rnorm(300))
head(DT)
setkey(DT,x)
DT["a"]
DTl <- data.table(x=c('a', 'a', 'b', 'dtl'), y=1:4)
DT2 <- data.table(x=c('a', 'b', 'dt2'), z=5:7)
setkey(DTl, x); setkey(DT2, x)
merge(DTl, DT2)
big_df <- data.frame(x=rnorm(1E6), y=rnorm(1E6))
file<- tempfile()
write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep="\t", quote=FALSE)
system.time(fread(file))
system.time(read.table(file, header=TRUE, sep="\t"))
str(download.file)
csvUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
pdfUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf"
download.file(csvUrl, destfile = "./data/UScommunities.csv", method = "curl")
download.file(pdfUrl, destfile = "./data/UScommunities.pdf", method = "curl")
list.files("./data")
uscom <- read.csv("data/UScommunities.csv")
head(uscom)
View(uscom)
str(uscom)
expensive <- uscom[uscom$VAL >= 1000000]
expensive <- uscom[uscom$VAL > 1000000]
uscom[uscom$VAL > 1000000]
uscom[uscom$VAL]
uscom <- read.csv("data/UScommunities.csv")
head(uscom)
str(uscom)
uscom$VAL
uscom[uscom$VAL==24]
val_counts <- table(uscom$VAL)
sum(uscom$VAL == 24)
# Print count for VAL=24
val_24_count <- val_counts[as.character(24)]
print(val_24_count)
# Print count for VAL=24
val_24_count <- val_counts[as.character(24)]
print(val_24_count)
# Print count for VAL=24
val_24_count <- val_counts[as.character(24)]
print(val_24_count)
# Print count for VAL=24
val_24_count <- val_counts[as.character(24)]
print(val_24_count)
# Print count for VAL=24
val_24_count <- val_counts[as.character(24)]
print(val_24_count)
# Print count for VAL=24
val_24_count <- val_counts[as.character(24)]
print(val_24_count)
View(uscom)
dat <- read.csv("data/gas.csv")
dat <- read.csv("data/gas.csv")
dat
sum(dat$Zip*dat$Ext,na.rm=T)
View(dat)
dat <- read.csv("data/gas.csv",sep = ";")
dat
sum(dat$Zip*dat$Ext,na.rm=T)
xmlURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(xmlURL, useInternal = TRUE)
library(XML)
xmlURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(xmlURL, useInternal = TRUE)
library(XML)
library(RCurl)
xmlURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xmlData <- getURL(xmlURL)
doc <- xmlTreeParse(xmlData, useInternal = TRUE)
library(XML)
library(RCurl)
xmlURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xmlData <- getURL(xmlURL)
doc <- xmlTreeParse(xmlData, useInternal = TRUE)
library(XML)
library(RCurl)
xmlURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xmlData <- getURL(xmlURL)
doc <- xmlTreeParse(xmlData)
library(XML)
library(RCurl)
xmlURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xmlData <- getURL(xmlURL)
doc <- xmlTreeParse(xmlData, useInternal = TRUE)
install.packages("rvest")
install.packages("xml2")
# load required packages
library(rvest)
library(xml2)
# fetch the XML data
xml_data <- read_xml("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
# get all the zipcodes
zipcodes <- xml_data %>% xml_find_all("//zipcode") %>% xml_text()
# count the number of restaurants with zipcode 21231
sum(zipcodes == "21231")
DT  <- fread("data/getdata_data_ss06pid.csv")
head(DT)
View(DT)
